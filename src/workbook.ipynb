{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architectural_principles import ArchitecturalConstraints, State\n",
    "from train import ExperimentManager\n",
    "from environment import ArchitecturalEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'env': {\n",
    "        'grid_size': (10, 10),\n",
    "        'max_steps': 500,\n",
    "        'required_rooms': ArchitecturalConstraints.default_rooms()\n",
    "    },\n",
    "    'algorithms': {\n",
    "        'value_iteration': {\n",
    "            'gamma': .95,\n",
    "            'theta': 0.001\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def_rooms = ArchitecturalConstraints.default_rooms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "7",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iterations):\n\u001b[0;32m     58\u001b[0m     new_state_value_map \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(state_value_map)\n\u001b[1;32m---> 60\u001b[0m     expanded_states \u001b[38;5;241m=\u001b[39m expand_states(sampled_states, actions)\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# Update value function\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m sampled_states:\n",
      "Cell \u001b[1;32mIn[7], line 44\u001b[0m, in \u001b[0;36mexpand_states\u001b[1;34m(sampled_states, actions)\u001b[0m\n\u001b[0;32m     42\u001b[0m env\u001b[38;5;241m.\u001b[39mset_state(state)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[1;32m---> 44\u001b[0m     next_state, reward, _, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# Add new state if it wasn't visited before\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     key \u001b[38;5;241m=\u001b[39m state_to_key(next_state)\n",
      "File \u001b[1;32mg:\\My Drive\\Harvard Coursework\\CS1840\\Project\\rl_final\\src\\environment.py:65\u001b[0m, in \u001b[0;36mArchitecturalEnvironment.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     63\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_room(action[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m action[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodify_room\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 65\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modify_room(action[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m action[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mremove_room\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     67\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remove_room(action[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mg:\\My Drive\\Harvard Coursework\\CS1840\\Project\\rl_final\\src\\environment.py:132\u001b[0m, in \u001b[0;36mArchitecturalEnvironment._modify_room\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Add modified room\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid[x:x\u001b[38;5;241m+\u001b[39mnew_width, y:y\u001b[38;5;241m+\u001b[39mnew_height] \u001b[38;5;241m=\u001b[39m room_id\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplaced_rooms[room_id][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (new_width, new_height)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_reward() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: 7"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "env = ArchitecturalEnvironment((10, 10), 50, def_rooms)\n",
    "init_state = env.reset()\n",
    "state_value_map = {}\n",
    "sampled_states = [init_state]\n",
    "actions = ExperimentManager(config)._get_action_space()\n",
    "num_iterations = 30\n",
    "max_states = 1000\n",
    "gamma = 0.95\n",
    "\n",
    "def state_to_key(state) -> str:\n",
    "    \"\"\"Convert state to a hashable key.\"\"\"\n",
    "    return str(state.layout) + str(state.placed_rooms) + str(state.current_step)\n",
    "\n",
    "def sample_initial_states():\n",
    "    \"\"\"Generate initial random states.\"\"\"\n",
    "    states = []\n",
    "    env.reset()\n",
    "    for room_name in env.required_rooms.keys():\n",
    "        action = {\n",
    "            \"type\": \"add_room\",\n",
    "            \"params\": {\n",
    "                \"name\": room_name,\n",
    "                \"room_type\": env.required_rooms[room_name].room_type,\n",
    "                \"position\": (\n",
    "                    np.random.randint(0, env.grid_size[0] - 1),\n",
    "                    np.random.randint(0, env.grid_size[1] - 1)\n",
    "                ),\n",
    "                \"size\": env.required_rooms[room_name].min_size,\n",
    "            },\n",
    "        }\n",
    "        env.step(action)\n",
    "        states.append(env._get_state())\n",
    "    return states\n",
    "\n",
    "\n",
    "def expand_states(sampled_states: list[State], actions: list[dict]):\n",
    "    # Expand states using valid actions\n",
    "    expanded_states = []\n",
    "    for state in sampled_states:\n",
    "        env.set_state(state)\n",
    "        for action in actions:\n",
    "            next_state, reward, _, _ = env.step(action)\n",
    "            # Add new state if it wasn't visited before\n",
    "            key = state_to_key(next_state)\n",
    "            if key not in state_value_map and len(state_value_map) < max_states:\n",
    "                state_value_map[key] = 0.0\n",
    "                expanded_states.append(next_state)\n",
    "    return expanded_states\n",
    "\n",
    "# Sample initial states\n",
    "sampled_states = sample_initial_states()\n",
    "for state in sampled_states:\n",
    "    state_value_map[state_to_key(state)] = 0.0\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    new_state_value_map = copy.deepcopy(state_value_map)\n",
    "\n",
    "    expanded_states = expand_states(sampled_states, actions)\n",
    "\n",
    "    # Update value function\n",
    "    for state in sampled_states:\n",
    "        env.set_state(state)\n",
    "        max_next_value = 0\n",
    "        for action in actions:\n",
    "            next_state, reward, _, _ = env.step(action)\n",
    "            key = state_to_key(next_state)\n",
    "            max_next_value = max(max_next_value, reward + gamma * state_value_map.get(key, 0))\n",
    "\n",
    "        # Update the value of the current state\n",
    "        new_state_value_map[state_to_key(state)] = max_next_value\n",
    "\n",
    "    # Replace old value map with the new one\n",
    "    state_value_map = new_state_value_map\n",
    "\n",
    "    # Deduplicate states and merge expanded states\n",
    "    sampled_states.extend(expanded_states)\n",
    "    sampled_states = list({state_to_key(s): s for s in sampled_states}.values())\n",
    "    \n",
    "state_value_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
